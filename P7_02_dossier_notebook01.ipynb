{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Libraries import\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport re\nimport time\nimport gc\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom sklearn import decomposition\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, f1_score, fbeta_score, precision_score, recall_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import linear_model, neighbors\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV , train_test_split\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-05T16:09:35.714867Z","iopub.execute_input":"2021-12-05T16:09:35.715357Z","iopub.status.idle":"2021-12-05T16:09:38.655283Z","shell.execute_reply.started":"2021-12-05T16:09:35.715314Z","shell.execute_reply":"2021-12-05T16:09:38.654126Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## **Getting data from Kernel output and first preprocess**","metadata":{}},{"cell_type":"markdown","source":"Using the \"Home_credit_risk_data_modeling.csv\" which is the output from the choosen kernel (https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features) to get X_train_sample and X_test_sample.<br/>\nWe will only use X_train_sample for our project","metadata":{}},{"cell_type":"code","source":"df_data_mod = pd.read_csv('../input/home-risk-preprocess/Home_credit_risk_data_modeling.csv', index_col=0)\ndf_data_mod.info()\ncolumns_no_nan = [i for i in df_data_mod.columns if df_data_mod[i].isnull().sum() == 0]\ndf_train_sample = df_data_mod.loc[~(df_data_mod['TARGET'].isnull())]\ndf_test_sample = df_data_mod.loc[df_data_mod['TARGET'].isnull()]\ndel df_data_mod\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:09:50.412927Z","iopub.execute_input":"2021-12-05T16:09:50.413303Z","iopub.status.idle":"2021-12-05T16:10:53.184175Z","shell.execute_reply.started":"2021-12-05T16:09:50.413265Z","shell.execute_reply":"2021-12-05T16:10:53.183482Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Defining X and y with train data\nX = df_train_sample.drop(columns = ['TARGET','SK_ID_CURR','index']).copy()\ny = df_train_sample['TARGET'].copy()\n# keep SK_ID_CURR for later evantually\nindex_global_train_SK_ID_CURR = df_train_sample['SK_ID_CURR']\n# Checking inf\nnp.isinf(X).values.sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:10:56.700938Z","iopub.execute_input":"2021-12-05T16:10:56.701437Z","iopub.status.idle":"2021-12-05T16:10:58.941593Z","shell.execute_reply.started":"2021-12-05T16:10:56.701384Z","shell.execute_reply":"2021-12-05T16:10:58.940756Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Replace inf values by max() and min() values and check\ncol_min_max = {np.inf: X[np.isfinite(X)].max(),    # column-wise max\n              -np.inf: X[np.isfinite(X)].min()}    # column-wise min\n\nX = X.replace({col: col_min_max for col in X.columns})\nnp.isinf(X).values.sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:11:01.678554Z","iopub.execute_input":"2021-12-05T16:11:01.678876Z","iopub.status.idle":"2021-12-05T16:11:11.803858Z","shell.execute_reply.started":"2021-12-05T16:11:01.678845Z","shell.execute_reply":"2021-12-05T16:11:11.802745Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Checking NaN values\nX.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:11:14.486551Z","iopub.execute_input":"2021-12-05T16:11:14.487184Z","iopub.status.idle":"2021-12-05T16:11:14.945445Z","shell.execute_reply.started":"2021-12-05T16:11:14.487137Z","shell.execute_reply":"2021-12-05T16:11:14.944577Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Function for features detection before imputation, numerical continue or numerical discrete\ndef list_features_att(df):\n    '''Function to attribute to columns of a dataframe a category into a several list\n    it returns two lists.\n    --> Numerical: num_list\n    --> discrete_numerical: num_dis_list'''\n    \n    num_list = list()\n    num_dis_list = list()\n    for name in df.columns:\n        if df[name].nunique() < 10:\n            num_dis_list.append(name)\n        else:\n            num_list.append(name)\n    return num_list, num_dis_list","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:11:34.519428Z","iopub.execute_input":"2021-12-05T16:11:34.520469Z","iopub.status.idle":"2021-12-05T16:11:34.526829Z","shell.execute_reply.started":"2021-12-05T16:11:34.520418Z","shell.execute_reply":"2021-12-05T16:11:34.526061Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Imputation in function of the numeric format\nnumerical_cont_list, numerical_disc_list = list_features_att(X)\ntime_init = time.time()\n#imputation on numeric continue columns with 'mean' strategy\nX[numerical_cont_list] = SimpleImputer(strategy='mean').fit_transform(X[numerical_cont_list])\n#imputation on  discrete numeric columns with 'most_frequent' strategy\nX[numerical_disc_list] = SimpleImputer(strategy='most_frequent').fit_transform(X[numerical_disc_list])\nprint (f'time for imputation: {time.time() - time_init:.2f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:11:51.865745Z","iopub.execute_input":"2021-12-05T16:11:51.866273Z","iopub.status.idle":"2021-12-05T16:12:20.161329Z","shell.execute_reply.started":"2021-12-05T16:11:51.866236Z","shell.execute_reply":"2021-12-05T16:12:20.160250Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## **Sample our data to make ModelSearch easier**","metadata":{}},{"cell_type":"markdown","source":" We have 795 features and 307507 rows! Let's reduce our data with train_test_split with stratified option to keep 5% of our data.<br/>\n It will only be used for the search of a potential best model","metadata":{}},{"cell_type":"code","source":"# keeping only train result in our split\nX1,_,y1,_ = train_test_split(X, y, train_size=0.05, stratify=y, random_state=4)\n# verifying that our problem is still imbalanced\nfigure1 = plt.figure(figsize=(10,7), facecolor='w')\nplt.title('Répartion des crédits payés à temps et avec difficultés dans notre sample', fontweight='bold', pad=20)\nplt.axis('off')\nx = y1.value_counts()\nexpl = [0 if i/x.sum() > 0.02 else 0.8 for i in x]\nplt.pie(x, labels=[i for i in x.index], autopct=\"%.1f%%\", pctdistance=0.8,\n        explode=expl, textprops={'fontsize': 10, 'fontweight': 'bold'})\nplt.legend(['Remboursés', 'Difficultés de paiement'])\nplt.show()\nprint(f'sample features shape:{X1.shape}, sample target shape: {y1.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T12:29:02.960133Z","iopub.execute_input":"2021-12-05T12:29:02.960561Z","iopub.status.idle":"2021-12-05T12:29:09.403341Z","shell.execute_reply.started":"2021-12-05T12:29:02.960516Z","shell.execute_reply":"2021-12-05T12:29:09.401784Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Finally we have 15375 row with the same imbalanced state as our complete data","metadata":{}},{"cell_type":"markdown","source":"## **Applying splitting and standardScaler to the data reduced before searching for best model**","metadata":{}},{"cell_type":"code","source":"time_init = time.time()\n# Data split (80% of train set)\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size=0.8, stratify=y1, random_state=4)\n# Normalization of the imput data\nstd_scaler = StandardScaler()\nstd_scaler.fit(X1_train)\nX1_train = std_scaler.transform(X1_train)\nX1_test = std_scaler.transform(X1_test)\nprint (f'Time for Spliting and Normalize: {time.time() - time_init:.2f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T12:29:12.837953Z","iopub.execute_input":"2021-12-05T12:29:12.838311Z","iopub.status.idle":"2021-12-05T12:29:13.178400Z","shell.execute_reply.started":"2021-12-05T12:29:12.838279Z","shell.execute_reply":"2021-12-05T12:29:13.177003Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":" ## **Best model research: tests with SMOTE, RUS for balancing our problem**","metadata":{}},{"cell_type":"markdown","source":"### **Train dummy classifier for having a baseline on our test data**","metadata":{}},{"cell_type":"code","source":"dummy_const_mod = DummyClassifier(strategy='most_frequent', random_state=4)\ntime_init = time.time()\ndummy_const_mod.fit(X1_train, y1_train)\ntime_1 = time.time()\ny_pred_dumm_const_1 = dummy_const_mod.predict(X1_test)\ntime_2 = time.time()\ny_pred_pro_dumm_const_1 = dummy_const_mod.predict_proba(X1_test)[:,1]\n# create df for global model results\nsummary_result = list()\nsummary_result.append({'model':'Dummy_stratified', 'Score AUC':roc_auc_score(y1_test, y_pred_pro_dumm_const_1), \n                       'F1_score': f1_score(y1_test, y_pred_dumm_const_1), 'F2_score': fbeta_score(y1_test, y_pred_dumm_const_1, beta=2), \n                       'Precision_score': precision_score(y1_test,y_pred_dumm_const_1), 'Recall_score': recall_score(y1_test, y_pred_dumm_const_1),\n                       'Train Time(s)':time_1 - time_init, 'Predict Time(s)': time_2 - time_1,'Comment': 'test data score'})\ndf_summary_result1 = pd.DataFrame(summary_result)\ndf_summary_result1","metadata":{"execution":{"iopub.status.busy":"2021-12-05T12:29:24.175822Z","iopub.execute_input":"2021-12-05T12:29:24.176194Z","iopub.status.idle":"2021-12-05T12:29:24.224491Z","shell.execute_reply.started":"2021-12-05T12:29:24.176160Z","shell.execute_reply":"2021-12-05T12:29:24.223759Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### **Model selection with RandomSearchCV and reduced data**","metadata":{}},{"cell_type":"markdown","source":"#### RandomSearchCV with Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Defining the samplers\nsmote = SMOTE(random_state=4)\nrus = RandomUnderSampler(random_state=4)\n\n# create the imblearn pipeline and grid parameters\n# be carefull be sure to use pipeline from imblearn to use SMOTE sampler, it will not evaluate result on y_test create with it\ntime_init = time.time()\nscores_CV5_1 = list()\nfor sampler in [smote, rus]:\n    pipe = Pipeline([('Sampling', sampler), ('classifier', linear_model.LogisticRegression(random_state=4, max_iter=10000))])\n    param_grid1 = {'classifier__C':np.logspace(1,3,100)}\n    # perfomring rand search CV\n    gride_mod = RandomizedSearchCV(pipe, param_distributions = param_grid1, cv = 5, scoring='roc_auc', n_iter=10, n_jobs=-1, random_state=4)\n    gride_mod.fit(X1_train, y1_train)\n    scores_CV5_1.append({'model':'Logistic_Regression', 'best_score AUC':gride_mod.best_score_, 'best parameters':gride_mod.best_params_,\n                       'Best model':gride_mod.best_estimator_,'Refit Time(s)':gride_mod.refit_time_, 'Comment':f'{sampler} train data'})\n\n# create df results\nprint(f'RandomSearchCV execution time(s): {time.time() - time_init}')\ndf_scores_CV5_1 = pd.DataFrame(scores_CV5_1)\ndf_scores_CV5_1","metadata":{"execution":{"iopub.status.busy":"2021-12-05T12:29:29.209006Z","iopub.execute_input":"2021-12-05T12:29:29.209771Z","iopub.status.idle":"2021-12-05T13:18:38.389194Z","shell.execute_reply.started":"2021-12-05T12:29:29.209716Z","shell.execute_reply":"2021-12-05T13:18:38.387877Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### RandomSearchCV with KNeighborsClassifier","metadata":{}},{"cell_type":"code","source":"# Defining the samplers\nsmote = SMOTE(random_state=4)\nrus = RandomUnderSampler(random_state=4)\n\n# create the imblearn pipeline and grid parameters\n# be carefull be sure to use pipeline from imblearn to use SMOTE sampler, it will not evaluate result on y_test create with it\ntime_init = time.time()\nscores_CV5_1 = list()\nfor sampler in [smote, rus]:\n    pipe = Pipeline([('Sampling', sampler), ('classifier', neighbors.KNeighborsClassifier())])\n    param_grid1 = {'classifier__n_neighbors':range(2,300,1)}\n    # perfomring rand search CV\n    gride_mod = RandomizedSearchCV(pipe, param_distributions = param_grid1, cv = 5, scoring='roc_auc', n_iter=10, n_jobs=-1, random_state=4)\n    gride_mod.fit(X1_train, y1_train)\n    scores_CV5_1.append({'model':'Kneighbors classifier', 'best_score AUC':gride_mod.best_score_, 'best parameters':gride_mod.best_params_,\n                       'Best model':gride_mod.best_estimator_,'Refit Time(s)':gride_mod.refit_time_, 'Comment':f'{sampler} train data'})\n   \n# create df results\nprint(f'RandomSearchCV execution time(s): {time.time() - time_init}')\ndf_scores_CV5_1 = df_scores_CV5_1.append(scores_CV5_1, ignore_index=True)\ndf_scores_CV5_1","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:24:57.447708Z","iopub.execute_input":"2021-12-05T13:24:57.448023Z","iopub.status.idle":"2021-12-05T13:55:40.716947Z","shell.execute_reply.started":"2021-12-05T13:24:57.447990Z","shell.execute_reply":"2021-12-05T13:55:40.715957Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### RandomSearchCV with RandomForest Classifier","metadata":{}},{"cell_type":"code","source":"# create the imblearn pipeline and grid parameters\n# be carefull be sure to use pipeline from imblearn to use SMOTE sampler, it will not evaluate result on y_test create with it\ntime_init = time.time()\nscores_CV5_1 = list()\nfor sampler in [smote, rus]:\n    pipe = Pipeline([('Sampling', sampler), ('classifier', RandomForestClassifier(random_state=4))])\n    param_grid1 = {'classifier__n_estimators':range(5,70,5), 'classifier__max_depth': [5, 7, 10]}\n    # perfomring rand search CV\n    gride_mod = RandomizedSearchCV(pipe, param_distributions = param_grid1, cv = 5, scoring='roc_auc', n_iter=10, n_jobs=-1, random_state=4)\n    gride_mod.fit(X1_train, y1_train)\n    scores_CV5_1.append({'model':'RandomForest classifier', 'best_score AUC':gride_mod.best_score_, 'best parameters':gride_mod.best_params_,\n                       'Best model':gride_mod.best_estimator_,'Refit Time(s)':gride_mod.refit_time_, 'Comment':f'{sampler} train data'})\n\n# create df results\nprint(f'RandomSearchCV execution time(s): {time.time() - time_init}')\ndf_scores_CV5_1 = df_scores_CV5_1.append(scores_CV5_1, ignore_index=True)\ndf_scores_CV5_1","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:55:56.058964Z","iopub.execute_input":"2021-12-05T13:55:56.059321Z","iopub.status.idle":"2021-12-05T13:58:04.835166Z","shell.execute_reply.started":"2021-12-05T13:55:56.059286Z","shell.execute_reply":"2021-12-05T13:58:04.834242Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### RandomSearchCV with XGBoost classifier","metadata":{}},{"cell_type":"code","source":"# create the imblearn pipeline and grid parameters\n# be carefull be sure to use pipeline from imblearn to use SMOTE sampler, it will not evaluate result on y_test create with it\ntime_init = time.time()\nscores_CV5_1 = list()\nfor sampler in [smote, rus]:\n    pipe = Pipeline([('Sampling', sampler), ('classifier', XGBClassifier(use_label_encoder=False, random_state=4, eval_metric='mlogloss'))])\n    param_grid1 = {'classifier__n_estimators':range(5,70,5), 'classifier__max_depth': [5, 7, 10], 'classifier__learning_rate':[0.1, 0.5]}\n    # perfomring rand search CV\n    gride_mod = RandomizedSearchCV(pipe, param_distributions = param_grid1, cv = 5, scoring='roc_auc', n_iter=10, n_jobs=-1, random_state=4)\n    gride_mod.fit(X1_train, y1_train)\n    scores_CV5_1.append({'model':'XGBoost classifier', 'best_score AUC':gride_mod.best_score_, 'best parameters':gride_mod.best_params_,\n                       'Best model':gride_mod.best_estimator_,'Refit Time(s)':gride_mod.refit_time_, 'Comment':f'{sampler} train data'})\n\n# create df results\nprint(f'RandomSearchCV execution time(s): {time.time() - time_init}')\ndf_scores_CV5_1 = df_scores_CV5_1.append(scores_CV5_1, ignore_index=True)\ndf_scores_CV5_1","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:58:15.889492Z","iopub.execute_input":"2021-12-05T13:58:15.889822Z","iopub.status.idle":"2021-12-05T14:38:10.521251Z","shell.execute_reply.started":"2021-12-05T13:58:15.889789Z","shell.execute_reply":"2021-12-05T14:38:10.520318Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#### RandomSearchCV with LGBM classifier","metadata":{}},{"cell_type":"code","source":"# create the imblearn pipeline and grid parameters\n# be carefull be sure to use pipeline from imblearn to use SMOTE sampler, it will not evaluate result on y_test create with it\ntime_init = time.time()\nscores_CV5_1 = list()\nfor sampler in [smote, rus]:\n    pipe = Pipeline([('Sampling', sampler), ('classifier', LGBMClassifier(random_state=4))])\n    param_grid1 = {'classifier__n_estimators':range(5,70,5), 'classifier__max_depth': [5, 7, 10], 'classifier__learning_rate':[0.1, 0.5]}\n    # perfomring rand search CV\n    gride_mod = RandomizedSearchCV(pipe, param_distributions = param_grid1, cv = 5, scoring='roc_auc', n_iter=10, n_jobs=-1, random_state=4)\n    gride_mod.fit(X1_train, y1_train)\n    scores_CV5_1.append({'model':'LGBM classifier', 'best_score AUC':gride_mod.best_score_, 'best parameters':gride_mod.best_params_,\n                       'Best model':gride_mod.best_estimator_,'Refit Time(s)':gride_mod.refit_time_, 'Comment':f'{sampler} train data'})\n\n# create df results\nprint(f'RandomSearchCV execution time(s): {time.time() - time_init}')\ndf_scores_CV5_1 = df_scores_CV5_1.append(scores_CV5_1, ignore_index=True)\ndf_scores_CV5_1","metadata":{"execution":{"iopub.status.busy":"2021-12-05T14:39:10.863269Z","iopub.execute_input":"2021-12-05T14:39:10.863614Z","iopub.status.idle":"2021-12-05T14:42:21.133551Z","shell.execute_reply.started":"2021-12-05T14:39:10.863577Z","shell.execute_reply":"2021-12-05T14:42:21.132549Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":" #### Validation scores over reduced data","metadata":{}},{"cell_type":"code","source":"# create list with probability on the validation test\ny_pred_prob_list = list()\n# add dummy classifier result to problist for our basline\ny_pred_prob_list.append(y_pred_pro_dumm_const_1)\n# Results for each best models with test data\nfor i in df_scores_CV5_1.index:\n    model = df_scores_CV5_1.iloc[i,3]\n    time_init = time.time()\n    time_1 = time.time()\n    y_pred_model = model.predict(X1_test)\n    time_2 = time.time()\n    y_pred_prob_model = model.predict_proba(X1_test)[:,1]\n    # filling df with results for each models\n    summary_result = list()\n    summary_result.append({'model': df_scores_CV5_1.iloc[i, 0], 'Score AUC':roc_auc_score(y1_test, y_pred_prob_model), \n                       'F1_score': f1_score(y1_test, y_pred_model), 'F2_score': fbeta_score(y1_test, y_pred_model, beta=2),\n                        'Precision_score': precision_score(y1_test,y_pred_model), 'Recall_score': recall_score(y1_test, y_pred_model),\n                       'Train Time(s)':df_scores_CV5_1.iloc[i, 4], 'Predict Time(s)': time_2 - time_1 , \n                        'Comment': f'test data score with {df_scores_CV5_1.iloc[i, 5]}'})\n    df_summary_result1 = df_summary_result1.append(summary_result, ignore_index=True)\n    y_pred_prob_list.append(y_pred_prob_model)\ndf_summary_result1","metadata":{"execution":{"iopub.status.busy":"2021-12-05T14:44:27.763059Z","iopub.execute_input":"2021-12-05T14:44:27.763647Z","iopub.status.idle":"2021-12-05T14:49:22.406398Z","shell.execute_reply.started":"2021-12-05T14:44:27.763607Z","shell.execute_reply":"2021-12-05T14:49:22.405732Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"##### ROC and Precision/Recall curves data reduced","metadata":{}},{"cell_type":"code","source":"# Function to plot ROC and Precision-Recall curves\ndef ROC_PR_curves(test_labels, list_pred_proba, models_name):\n    '''Function to plot ROC and PR curves\n    test_labels --> True labels to predicts, y_test for example 1_D\n    list_pred_proba --> models predicts probalbility 1-D\n    models_name --> list of models names in the same order than list_predict_proba'''\n    # figure init\n    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,7))\n    plt.suptitle('ROC / PR curves for our models (validation data)', fontweight='bold')\n    ax1.plot([0,1], [0,1], 'k--')\n    ax2.plot([0,1], [0,0], 'k--')\n    ax1.set_title('ROC')\n    ax1.set_xlabel('False Positive Rate')\n    ax1.set_ylabel('True Positive Rate')\n    ax2.set_title('Precision / Recall')\n    ax2.set_xlabel('Recall')\n    ax2.set_ylabel('Precision')\n    # counter for getting models names\n    count=0\n    for pred_prob in list_pred_proba:\n        # fpr and tpr calcul\n        fpr, tpr, _ = roc_curve(test_labels, pred_prob)\n        # Precision and recall calcul\n        pr, rec, _ = precision_recall_curve(test_labels, pred_prob)\n        # Plot ROC curve\n        ax1.plot(fpr, tpr, label=f'{models_name[count]} / AUC={roc_auc_score(test_labels, pred_prob):.3f}')\n        # Plot PR curve\n        ax2.plot(rec, pr, label=models_name[count])\n        count+=1\n    ax1.legend()\n    # ax2.legend() optionnal\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:05:21.042920Z","iopub.execute_input":"2021-12-05T15:05:21.043383Z","iopub.status.idle":"2021-12-05T15:05:21.055184Z","shell.execute_reply.started":"2021-12-05T15:05:21.043339Z","shell.execute_reply":"2021-12-05T15:05:21.054098Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"ROC_PR_curves(y1_test, y_pred_prob_list, df_summary_result1['model'])","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:03:22.771902Z","iopub.execute_input":"2021-12-05T15:03:22.773069Z","iopub.status.idle":"2021-12-05T15:03:23.412048Z","shell.execute_reply.started":"2021-12-05T15:03:22.773015Z","shell.execute_reply":"2021-12-05T15:03:23.410966Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"--> Our models are better has random model with the probability to reject on the most frequent class (never here) <br/>\n--> Best scores are obtained with RUS and two models (RandomForest line 6 / LGBM line 10) seems to compete in terms of: <br>\n* AUC scoring (it is our scoring method)\n* Train time\n* F2 score (interresting because it advantages the recall score over precision and this is what we want on our problematic)","metadata":{}},{"cell_type":"markdown","source":" #### Validation scores for our two best models over all our data with RUS","metadata":{}},{"cell_type":"code","source":"# try to garbage X1 and y1 for memory usage\ndel X1, y1, X1_train, y1_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:07:30.860801Z","iopub.execute_input":"2021-12-05T15:07:30.862144Z","iopub.status.idle":"2021-12-05T15:07:31.593860Z","shell.execute_reply.started":"2021-12-05T15:07:30.862071Z","shell.execute_reply":"2021-12-05T15:07:31.592646Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# spliting and use our overall data\ntime_init = time.time()\n# Data split (80% of train set)\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=4)\n# get X_train and X_test index\nX_train_index = X_train.index\nX_test_index = X_test.index\n# Normalization of the imput data\nstd_scaler = StandardScaler()\nstd_scaler.fit(X_train)\nX_train = std_scaler.transform(X_train)\nX_test = std_scaler.transform(X_test)\nprint (f'Time for Spliting and Normalize: {time.time() - time_init:.2f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:07:59.025909Z","iopub.execute_input":"2021-12-05T15:07:59.026284Z","iopub.status.idle":"2021-12-05T15:08:14.478090Z","shell.execute_reply.started":"2021-12-05T15:07:59.026251Z","shell.execute_reply":"2021-12-05T15:08:14.477183Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Trying our two RUS best model (line 5 and line 9 of our first results df_scores_CV5_1)\n# defining new list for proba\nsummary_result1 = list()\ny_pred_prob_list1 = list()\nfor i in [5, 9]:\n    model = df_scores_CV5_1.iloc[i,3]\n    time_init = time.time()\n    model.fit(X_train, y_train)\n    time_1 = time.time()\n    y_pred_model = model.predict(X_test)\n    time_2 = time.time()\n    y_pred_prob_model = model.predict_proba(X_test)[:,1]\n    # filling list with results for each models\n    summary_result1.append({'model': df_scores_CV5_1.iloc[i, 0], 'Score AUC':roc_auc_score(y_test, y_pred_prob_model), \n                       'F1_score': f1_score(y_test, y_pred_model), 'F2_score': fbeta_score(y_test, y_pred_model, beta=2),\n                        'Precision_score': precision_score(y_test,y_pred_model), 'Recall_score': recall_score(y_test, y_pred_model),\n                       'Train Time(s)':df_scores_CV5_1.iloc[i, 4], 'Predict Time(s)': time_2 - time_1 , 'Comment': df_scores_CV5_1.iloc[i, 5]})\n    y_pred_prob_list1.append(y_pred_prob_model)\ndf_summary_result2 = pd.DataFrame(summary_result1)\ndf_summary_result2","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:10:24.029706Z","iopub.execute_input":"2021-12-05T15:10:24.030783Z","iopub.status.idle":"2021-12-05T15:10:47.000125Z","shell.execute_reply.started":"2021-12-05T15:10:24.030703Z","shell.execute_reply":"2021-12-05T15:10:46.998987Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"##### ROC and Precision/Recall curves","metadata":{}},{"cell_type":"code","source":"ROC_PR_curves(y_test, y_pred_prob_list1, df_summary_result2['model'])","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:15:44.516205Z","iopub.execute_input":"2021-12-05T15:15:44.516647Z","iopub.status.idle":"2021-12-05T15:15:45.012934Z","shell.execute_reply.started":"2021-12-05T15:15:44.516599Z","shell.execute_reply":"2021-12-05T15:15:45.011823Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"--> We select LGBM for the next with parameters:<br>\n* n_estimator = 60\n* max_depth = 7\n* learning_rate = 0.1\n* random_state=4 <br>\n\n--> We will try a GirdSearchCV around these parameters on a custom metric with this model","metadata":{}}]}